<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Varun Gangal</title>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-136414409-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-136414409-1');
</script>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category"></div>
<div class="menu-item"><a href="index.html">Home</a></div>
<!--<div class="menu-item"><a href="rinterests.html">Research&nbsp;Interests</a></div>-->
<!--<div class="menu-item"><a href="pub.html">Publications</a></div>-->
<div class="menu-item"><a href="sced.html">SCDE Dataset</a></div>
<div class="menu-item"><a href="misc.html">Miscellaneous</a></div>
<div class="menu-item"><a href="contact.html">Contact</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Varun Gangal</h1>
</div>
<table class="imgtable"><tr>
<!--<img src="Varun_NIPS_small.jpg" alt="Varun Gangal" />&nbsp;</td>-->
<td align="left"><br clear="left"/><p>I'm a PhD student  with the
<a href="https://www.lti.cs.cmu.edu">Language Technologies Institute</a>
at <a href="http://www.cmu.edu">CMU</a>,  
where I am advised by <a href="https://scholar.google.com/citations?user=PUFxrroAAAAJ">Prof. Eduard Hovy</a>. My research is broadly on language generation, with specific interests in <a href="https://www.aclweb.org/anthology/W17-4902.pdf">style transfer</a>, <a href="https://aclweb.org/anthology/P18-1154.pdf">data-to-text generation</a>,  <a href="https://arxiv.org/abs/2104.06669">story and narrative generation</a> and <a href="https://arxiv.org/abs/2010.01794">low-resource</a> &amp; <a href="https://aclanthology.org/D17-1315.pdf">creative generation</a>. 
</br>
<img style="padding: 12px;" src="Varun_AAAI2020_small.jpg" alt="Varun Gangal" align="right"/>&nbsp;
</br>
As a natural development  of my interest in low-resource &amp; creative generation, I became increasingly piqued about data augmentation (DA) for generation, leading to several fruitful research directions:
<ol>
<li> <a href="https://aclanthology.org/2020.deelio-1.4.pdf">Devising lightweight DA strategies</a> to finetune conditional generators like GPT-2. </li> 
<li> <a href="https://aclanthology.org/2021.findings-acl.357.pdf">Augmenting reference sets for dialog generation</a>, improving evaluation via automatic metrics like BLEU for no added cost. </li>
<li> A comprehensive <a href="https://aclanthology.org/2021.findings-acl.84.pdf">survey</a> on recent DA methods in NLP - we also try sensitizing the NLP community about lacunae, e.g w.r.t CV research, besides outlining challenges for the future. We maintain a live <a href="https://github.com/styfeng/DataAug4NLP">git repo</a> and <a href="https://arxiv.org/abs/2105.03075">arXiv</a> for this - <a href="https://github.com/styfeng/DataAug4NLP/blob/main/rules.md">send us a PR</a> to add your method onto both! </li>
<li> Data Augmentation for improving plausibility and fluency of Concept-to-Text Generation by:<br/><br/>
<ol style="font-size: 0.92em;"  >
<li> <a href="https://arxiv.org/abs/2108.06643">Example-level augmentation strategies</a> like knowledge-guided side-information and 'self-introspection'</li>
<li> <a href="https://arxiv.org/abs/2109.03892">Indirectly grounding through the visual modality</a> via captions of retrieved images.</li>
</ol>
</ol>

Corollary of my interest in story-level generation, some of my work circa 2020 also investigated probing extra-sentential abilities of contextual representations, such as <a href="https://aclanthology.org/2020.blackboxnlp-1.1.pdf">locating event arguments</a> and <a href="https://www.aclweb.org/anthology/2020.acl-main.502/">infilling whole sentences</a> a.k.a ``sentence cloze".
 </br>

<br/>
In the recent year, I have also been involved in co-organizing many collaborative NLP research efforts, such as:
<ol>
<li> The upcoming <a href="https://ctrlgenworkshop.github.io">Controllable Generative Modelling in Language and Vision Workshop</a> (CtrlGen) at <b><a href="https://nips.cc">NEURIPS'21</a></b> [Note: We're inviting Submissions for <a href="https://ctrlgenworkshop.github.io/CFP.html">Papers</a> as well as <a href="https://ctrlgenworkshop.github.io/demos.html">Demos</a>!] <p style="color:red;"><b>Deadline: September 30th!</b></p></li>
<li> The GEM <a href="https://gem-benchmark.com">benchmark</a>, associated <a href="https://gem-benchmark.com/workshop">workshop</a>@ACL'21, and <a href="https://aclanthology.org/2021.gem-1.10/">paper</a> for better and standardized evaluation and comparison of NLG models and systems - a parallel to <a href="https://gluebenchmark.com/tasks">GLUE</a> for generation <br/></li>
<li> I was also specifically involved in the <b>challenge sets</b> submodule of GEM, where we came up with domain-shifted sets under a unified theme for NLG tasks in our benchmark, using various perturbation [backtranslation], sub-selection [length] and other domain shift [diachronic] strategies. Our <a href="https://openreview.net/forum?id=CSi1eu_2q96">work</a> was accepted @ <a href="https://openreview.net/group?id=NeurIPS.cc/2021/Track/Datasets_and_Benchmarks/Round1">
NEURIPS'21 Datasets and Benchmarks Track</a>! 
<li> The NL-Augmenter participative <a href="https://github.com/GEM-benchmark/NL-Augmenter">repository</a> and benchmark, which provides a structure for NLPers to contribute and evaluate task-specific data augmentations a.k.a transformations, as well as subset selection strategies a.k.a filters. We aim to create a large, usable suite (<b>close to 100 and counting!</b>) of transformations and filters leveraging wisdom-of-the-crowd - opening the door to more systematic analysis and deployment of data augmentation/robustness evaluation.</li> 
</ol>

<!--My <b>broad interests</b> lie in the field of <b>Natural Language Processing</b>. More specifically, I am interested in <b>Natural Language Generation</b> (NLG), especially NLG tasks which involve <b>creativity</b> or <b>explanation</b>. Some problems I have worked on recently include <a href="https://arxiv.org/abs/1707.01176">portmanteau generation</a> and <a href="https://arxiv.org/abs/1707.08852">generating explainable stock market predictions</a>.   <br /></p> -->
<p>Before CMU, I graduated with a Dual Degree (B.Tech+M.Tech) in <a href="http://www.cse.iitm.ac.in/">Computer Science and Engineering</a>
from <a href="https://www.iitm.ac.in/">IIT Madras</a> in 2016. During my thesis year, I was advised by <a href="http://www.cse.iitm.ac.in/~ravi/">Prof. Ravindran</a> and <a href="https://scholar.google.com/citations?user=1pMBYn8AAAAJ&hl=en">Ramasuri Narayanam</a> from IBM Research, working on Social Network Analysis problems such as <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12137/12220">centrality measures</a> and <a href="http://arxiv.org/pdf/1606.05065.pdf">influence maximization</a> </p>
</a></p>
<!--<p>Here is a link to my <a href="VarunGangalCV.pdf">CV</a>.</p>-->
<p>For an overview of my published research and preprints, you can also check out my <a href="https://scholar.google.com/citations?user=rWZq2nQAAAAJ&hl=en">Google Scholar</a> profile.</p>
</td></tr></table>
<div id="footer">
<div id="footer-text">
Page generated 2021-09-10, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>




















