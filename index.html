<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Varun Gangal</title>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-136414409-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-136414409-1');
</script>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category"></div>
<div class="menu-item"><a href="index.html">Home</a></div>
<!--<div class="menu-item"><a href="rinterests.html">Research&nbsp;Interests</a></div>-->
<!--<div class="menu-item"><a href="pub.html">Publications</a></div>-->
<div class="menu-item"><a href="sced.html">SCDE Dataset</a></div>
<div class="menu-item"><a href="misc.html">Miscellaneous</a></div>
<div class="menu-item"><a href="contact.html">Contact</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Varun Gangal</h1>
</div>
<table class="imgtable"><tr>
<!--<img src="Varun_NIPS_small.jpg" alt="Varun Gangal" />&nbsp;</td>-->
<td align="left"><br clear="left"/><p>I'm a PhD student  with the
<a href="https://www.lti.cs.cmu.edu">Language Technologies Institute</a>
at <a href="http://www.cmu.edu">CMU</a>,  
where I am advised by <a href="https://scholar.google.com/citations?user=PUFxrroAAAAJ">Prof. Eduard Hovy</a>. My research is broadly on language generation, with specific interests in <a href="https://www.aclweb.org/anthology/W17-4902.pdf">style transfer</a>, <a href="https://aclweb.org/anthology/P18-1154.pdf">data-to-text generation</a>,  <a href="https://arxiv.org/abs/2104.06669">narrative generation</a> and <a href="https://arxiv.org/abs/2010.01794">low-resource</a> &amp; <a href="https://aclanthology.org/D17-1315.pdf">creative generation</a>. 
</br>
<img style="padding: 12px;" src="Varun_AAAI2020_small.jpg" alt="Varun Gangal" align="right"/>&nbsp;
</br>
As a natural development  of my interest in low-resource &amp; creative generation, I became increasingly piqued about data augmentation (DA), first specifically for generation, and then in general, leading to several fruitful research directions:
<ol>
<li> <a href="https://aclanthology.org/2020.deelio-1.4.pdf">Devising lightweight DA strategies</a> to finetune conditional generators like GPT-2. </li> 
<li> <a href="https://aclanthology.org/2021.findings-acl.357.pdf">Augmenting reference sets for dialog generation</a>, improving evaluation via automatic metrics like BLEU for no added cost. </li>
<li> A comprehensive <a href="https://aclanthology.org/2021.findings-acl.84.pdf">survey</a> on recent DA methods in NLP - we also try sensitizing the NLP community about lacunae, e.g w.r.t CV research and outline future challenges. We maintain a live <a href="https://github.com/styfeng/DataAug4NLP">git repo</a> and <a href="https://arxiv.org/abs/2105.03075">arXiv</a> - <a href="https://github.com/styfeng/DataAug4NLP/blob/main/rules.md">send us a PR</a> to add your method onto both! </li>
<li> DA for improving commonsense plausibility and fluency of Concept-to-Text Generation by:<br/><br/>
<ol style="font-size: 0.92em;"  >
<li> <a href="https://arxiv.org/abs/2108.06643">Example-level augmentation strategies</a> like knowledge-guided side-information and 'self-introspection' (&#127942; <b><a href="https://inlg2021.github.io/pages/papers.html">Best Long Paper</a></b> @ <a href="https://inlg2021.github.io/index.html">INLG 2021</a>) </li>
<li> <a href="https://arxiv.org/abs/2109.03892">Indirectly grounding through the visual modality</a> via captions of retrieved images.</li>
</ol>
</ol>

Corollary of my interest in narrative generation, some of my work circa 2020 investigated probing extra-sentential abilities of contextual representations, such as <a href="https://aclanthology.org/2020.blackboxnlp-1.1.pdf">locating event arguments</a> and <a href="https://www.aclweb.org/anthology/2020.acl-main.502/">infilling whole sentences</a> a.k.a ``sentence cloze".
 </br>

<br/>
In the past few years, I have also been involved in co-organizing many collaborative NLP research efforts, such as:
<ol>
<li> The <a href="https://ctrlgenworkshop.github.io">Controllable Generative Modelling in Language and Vision Workshop</a> (CtrlGen) at <b><a href="https://nips.cc">NEURIPS'21</a></b>, which aimed to explore controllability, disentanglement and manipulation for language and vision tasks. We  solicited submissions for <a href="https://ctrlgenworkshop.github.io/CFP.html">Papers</a> as well as <a href="https://ctrlgenworkshop.github.io/demos.html">Demos</a>. Checkout the <a href="https://neurips.cc/virtual/2021/workshop/21886">proceedings page</a> for talk vids, slides,  accepted paper info and more. <p style="color:red;"><b></b></p></li>
<li> The GEM <a href="https://gem-benchmark.com">benchmark</a>, associated <a href="https://gem-benchmark.com/workshop">workshop</a>@ACL'21, and <a href="https://aclanthology.org/2021.gem-1.10/">paper</a> for better and standardized evaluation and comparison of NLG models and systems - a parallel to <a href="https://gluebenchmark.com/tasks">GLUE</a> for generation <br/></li>
<li>The <b>challenge sets</b> submodule of GEM, where we built domain-shifted sets under a unified theme for NLG tasks in our benchmark, using various perturbation [backtranslation], sub-selection [length] and other domain shift [diachronic] strategies. Our <a href="https://openreview.net/forum?id=CSi1eu_2q96">work</a> was accepted @ <a href="https://openreview.net/group?id=NeurIPS.cc/2021/Track/Datasets_and_Benchmarks/Round1">
NEURIPS'21 Datasets &amp; Benchmarks Track</a>! 
<li> The NL-Augmenter participative <a href="https://github.com/GEM-benchmark/NL-Augmenter">repository</a> and benchmark, which provides a structure for NLPers to contribute and evaluate task-specific data augmentations a.k.a transformations, as well as subset selection strategies a.k.a filters. We aim to create a large, usable suite (<b>~140 and counting!</b>) of transformations and filters leveraging wisdom-of-the-crowd - opening the door to more systematic analysis and deployment of data augmentation/robustness evaluation.</li> 
</ol>

<!--My <b>broad interests</b> lie in the field of <b>Natural Language Processing</b>. More specifically, I am interested in <b>Natural Language Generation</b> (NLG), especially NLG tasks which involve <b>creativity</b> or <b>explanation</b>. Some problems I have worked on recently include <a href="https://arxiv.org/abs/1707.01176">portmanteau generation</a> and <a href="https://arxiv.org/abs/1707.08852">generating explainable stock market predictions</a>.   <br /></p> -->
<p>Before CMU, I graduated with a Dual Degree (B.Tech+M.Tech) in <a href="http://www.cse.iitm.ac.in/">Computer Science and Engineering</a>
from <a href="https://www.iitm.ac.in/">IIT Madras</a> in 2016. For my thesis, I was advised by <a href="http://www.cse.iitm.ac.in/~ravi/">Prof. Ravindran</a> and <a href="https://scholar.google.com/citations?user=1pMBYn8AAAAJ&hl=en">Ramasuri Narayanam</a> from IBM Research, working on Social Network Analysis problems related to unconventional social networks such as <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12137/12220">centrality measures for signed networks</a>, <a href="http://arxiv.org/pdf/1606.05065.pdf">influence maximization for hypergraphs</a> and multiplex graphs to model citation networks</p>
</a></p>
<!--<p>Here is a link to my <a href="VarunGangalCV.pdf">CV</a>.</p>-->
<p>For an overview of my published research and preprints, check out my <a href="https://scholar.google.com/citations?user=rWZq2nQAAAAJ&hl=en">Google Scholar</a> profile.</p>
<p style="text-align:center">
		<a href="mailto:vgangal@andrew.cmu.edu">Email</a> &nbsp;/&nbsp;
	    	<a href="VarunGangalCV.pdf">CV (Nov 2021)</a> &nbsp;/&nbsp;
	    	<a href="Varun_Research_Statement.pdf">Research Statement (Nov 2021)</a> &nbsp;/&nbsp;
	    	<a href="Varun_Thesis_Proposal_Latest.pdf">Thesis Proposal (Mar 2022)</a> &nbsp;/&nbsp;
	    	<a href="https://scholar.google.co.in/citations?user=rWZq2nQAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
	    	<a href="http://www.linkedin.com/in/varungangal/"> LinkedIn </a> &nbsp;/&nbsp;
		<a href="https://twitter.com/varungangal"> Twitter </a> &nbsp;/&nbsp;
		<a href="https://github.com/vgtomahawk"> GitHub </a>
</p>
</td></tr></table>
<!--
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:20px;width:75%;vertical-align:middle">
              <h2 align="left">News</h2>
				<ul style="list-style-type:'a'">
				  <li align="left">We're soliciting <a href="https://ctrlgenworkshop.github.io/CFP.html">paper</a> (Sept. 30 &#9200;) and <a href="https://ctrlgenworkshop.github.io/demos.html">demo</a> (Oct. 29 &#9200; )  for the <a href="https://ctrlgenworkshop.github.io/">CtrlGen</a> NeurIPS 2021 workshop.</a></li>
				  <li align="left"><b>Sept 21, 2021</b>: Overjoyed that  our <a href="https://aclanthology.org/2021.inlg-1.21/">SAPPHIRE paper</a> on concept-to-text generation was &#127942; <b><a href="https://inlg2021.github.io/pages/papers.html">Best Long Paper</a></b> @ <a href="https://inlg2021.github.io/index.html">INLG 2021</a>!</li>
				  <li align="left"><b>Sept. 2021</b>: Our visual grounding for commonsense in text generation <a href="https://arxiv.org/abs/2109.03892">paper</a> was accepted to the AKBC 2021 CSKB Workshop!</li>
				  <li><b>Sept. 2021</b>: Our personification identification <a href="https://styfeng.github.io/data/TADA_abstract.pdf">proposal/abstract</a> was accepted for presentation @ <a href="https://tada2021.org">TADA 2021</a>!</li>
				  <li><b>Sept. 2021</b>: Two preprints, one on <a href="https://arxiv.org/abs/2109.03892">visual grounding</a> and another on <a href="https://arxiv.org/abs/2104.06669">narrative reordering</a>, have been released on arXiv.</li>
				  <li><b>Aug. 2021</b>: <a href="https://vgtomahawk.github.io/">Varun</a> and I gave a talk for Google Research! Recording <a href="https://www.youtube.com/watch?v=kNBVesKUZCk&ab_channel=StevenFeng">here.</a></li>
				  <li><b>July 2021</b>: My amazing advisor <a href="https://www.cs.cmu.edu/~hovy/">Eduard Hovy</a> and co-author <a href="https://styfeng.github.io">Steven Feng</a> spoke about our <a href="https://aclanthology.org/2021.inlg-1.21/">data augmentation survey</a> on the Joe Rogan-esque <a href="https://thedataexchange.media/">Data Exchange Podcast</a>! Video <a href="https://www.youtube.com/watch?v=qmqyT_97Poc&ab_channel=GradientFlow">here</a>, audio and notes <a href="https://thedataexchange.media/data-augmentation-in-natural-language-processing/">here</a>.</li>
				  <li><b>July 2021</b>: Our <a href="https://ctrlgenworkshop.github.io/">CtrlGen: Controllable Generative Modeling in Language and Vision</a> workshop was accepted to NeurIPS 2021!</li>
				  <li><b>July 2021</b>: Our <a href="https://aclanthology.org/2021.inlg-1.21/">SAPPHIRE paper</a> on concept-to-text generation was accepted to INLG 2021!</li>
				  <li><b>May 2021</b>: Our <a href="https://aclanthology.org/2021.findings-acl.84/">data augmentation survey paper</a> was accepted to ACL 2021 Findings! It has received lots of attention on social media (e.g. this <a href="https://twitter.com/omarsar0/status/1391729605766262785">tweet</a>, Sebastian Ruder's <a href="https://newsletter.ruder.io/issues/github-copilot-the-perceiver-beyond-the-transformer-data-augmentation-nl-augmenter-research-communication-527358">NLP Newsletter</a>, Chinese news articles [<a href="https://mp.weixin.qq.com/s/7oeVUPg_zY3Bm_jywSqprg">1</a>,<a href="https://mp.weixin.qq.com/s/G6c1_YXtC5ZNXLjRuVNv4Q">2</a>,<a href="https://zhuanlan.zhihu.com/p/377437302">3</a>]) and was one of the top 10 hottest machine learning papers in May 2021.</li>
				</ul>
			</td>
          </tr>
      </td>
    </tr>
</table>-->

<div id="footer">
<div id="footer-text">
Page generated 2021-09-10, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
